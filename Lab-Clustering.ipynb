{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Based of the amazing work you did in the Movie Industry you've been recruited to the NBA! You are working as the VP of Analytics that helps support a head scout, Mr. Rooney, for the worst team in the NBA probably the Wizards. Mr. Rooney just heard about Data Science and thinks it can solve all the team's problems!!! He wants you to figure out a way to find players that are high performing but maybe not highly paid that you can steal to get the team to the playoffs! \n",
    "\n",
    "In this document you will work through a similar process that we did in class with the NBA data files will be in the canvas assignment, merging them together.\n",
    "\n",
    "Details: \n",
    "\n",
    "- Determine a way to use clustering to estimate based on performance if \n",
    "players are under or over paid, generally. \n",
    "\n",
    "- Then select players you believe would be best for your team and explain why. Do so in three categories: \n",
    "    * Examples that are not good choices (3 or 4) \n",
    "    * Several options that are good choices (3 or 4)\n",
    "    * Several options that could work, assuming you can't get the players in the good category (3 or 4)\n",
    "\n",
    "- You will decide the cutoffs for each category, so you should be able to explain why you chose them.\n",
    "\n",
    "- Provide a well commented and clean report of your findings in a separate notebook that can be presented to Mr. Rooney, keeping in mind he doesn't understand...anything. Include a rationale for variables you included in the model, details on your approach and a overview of the results with supporting visualizations. \n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Salary is the variable you are trying to understand \n",
    "- When interpreting you might want to use graphs that include variables that are the most correlated with Salary\n",
    "- You'll need to scale the variables before performing the clustering\n",
    "- Be specific about why you selected the players that you did, more detail is better\n",
    "- Use good coding practices, comment heavily, indent, don't use for loops unless totally necessary and create modular sections that align with some outcome. If necessary create more than one script,list/load libraries at the top and don't include libraries that aren't used. \n",
    "- Be careful for non-traditional characters in the players names, certain graphs won't work when these characters are included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "# needed to clarify that first row of salary data set were column headers\n",
    "\n",
    "salary_data = pd.read_csv(\"2025_salaries.csv\" , header=1)\n",
    "\n",
    "# there are several odd characters, latin-1 encoding was needed\n",
    "# needed to parse txt file with comma separation \n",
    "\n",
    "stats = pd.read_csv(\"nba_2025.txt\" , sep = \",\" , encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to merge data frames\n",
    "# will be doing an inner merge on the player column\n",
    "merged_data = pd.merge(salary_data, stats, on = \"Player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables that will not be needed or are duplicates\n",
    "# there are duplicates of players when they play for multiple teams\n",
    "# if a player played for multiple teams they have a row for each respective team\n",
    "# they have a third row with a \"2TM\" value in the team column\n",
    "# that row has their combined stats for that season\n",
    "# I will use that row and drop the other two duplicates\n",
    "\n",
    "# this pulls each row that is considered a duplicate\n",
    "# and the first ocurrance and puts those rows into a new DF\n",
    "\n",
    "duplicates = merged_data[merged_data.duplicated(subset=\"Player\", keep=False)]\n",
    "\n",
    "# this removes all rows where Team is 2TM\n",
    "# leaving us with a df of all unwanted rows\n",
    "\n",
    "unwanted_duplicates = duplicates[duplicates[\"Team\"] != \"2TM\" ] \n",
    "\n",
    "# this drops all of the rows that have the index that matches \n",
    "# the index of the merged_data\n",
    "# we are able to do this because we never reset the index\n",
    "\n",
    "unique_data = merged_data.drop(unwanted_duplicates.index)\n",
    "\n",
    "# now that we have removed all duplicates we can reset the index\n",
    "unique_data = unique_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the current salary column is called \"2025-26\"\n",
    "# lets rename that \"Salary\"\n",
    "\n",
    "unique_data = unique_data.rename(columns={\"2025-26\" : \"Salary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                  0\n",
       "Player                 0\n",
       "Tm                     0\n",
       "Salary                 4\n",
       "Rk                     0\n",
       "Age                    0\n",
       "Team                   0\n",
       "Pos                    0\n",
       "G                      0\n",
       "GS                     0\n",
       "MP                     0\n",
       "FG                     0\n",
       "FGA                    0\n",
       "FG%                    0\n",
       "3P                     0\n",
       "3PA                    0\n",
       "3P%                   19\n",
       "2P                     0\n",
       "2PA                    0\n",
       "2P%                    1\n",
       "eFG%                   0\n",
       "FT                     0\n",
       "FTA                    0\n",
       "FT%                    3\n",
       "ORB                    0\n",
       "DRB                    0\n",
       "TRB                    0\n",
       "AST                    0\n",
       "STL                    0\n",
       "BLK                    0\n",
       "TOV                    0\n",
       "PF                     0\n",
       "PTS                    0\n",
       "Trp-Dbl                0\n",
       "Awards               416\n",
       "Player-additional      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for mising values \n",
    "unique_data.isna().sum()\n",
    "\n",
    "# Since Salary is our target variable, we will drop rows where NA is present in this column\n",
    "# The other columns [3P%, 2P%, FT%, Awards] will be dropped altogether \n",
    "# dropping specific rows because they have missing values in these columns is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows where salary is NA\n",
    "\n",
    "unique_data = unique_data.dropna(subset=[\"Salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Player', 'Tm', 'Salary', 'Rk', 'Age', 'Team', 'Pos', 'G',\n",
       "       'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%',\n",
       "       'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK',\n",
       "       'TOV', 'PF', 'PTS', 'Trp-Dbl', 'Awards', 'Player-additional'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at all column names to determine which columns I want to keep\n",
    "# Columns kept should correlate to productivity and value\n",
    "\n",
    "COLS = unique_data.columns\n",
    "COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns kept will be [\"Player\" , \"Salary\" , \"FG\" , \"TRB\" , \"AST\" , \"STL\" , \"BLK\" ]\n",
    "# because they are columns that track offensive and defensive production on the court during a game\n",
    "\n",
    "keep_cols = [\"Player\" , \"Salary\" , \"FG\" , \"TRB\" , \"AST\" , \"STL\" , \"BLK\" ]\n",
    "unique_data = unique_data[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 412 entries, 0 to 411\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Player  412 non-null    str    \n",
      " 1   Salary  412 non-null    str    \n",
      " 2   FG      412 non-null    float64\n",
      " 3   TRB     412 non-null    float64\n",
      " 4   AST     412 non-null    float64\n",
      " 5   STL     412 non-null    float64\n",
      " 6   BLK     412 non-null    float64\n",
      "dtypes: float64(5), str(2)\n",
      "memory usage: 22.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Lets check the dtypes of each column \n",
    "unique_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns are of the correct dtype except for Salary \n",
    "# It should be a float but is a string\n",
    "# lets turn it into a float so we can standardize the data\n",
    "\n",
    "# first we need to strip the values of the $ and comma\n",
    "\n",
    "unique_data[\"Salary\"] = (\n",
    "    unique_data[\"Salary\"]\n",
    "    .str.replace(\"$\" , \"\", regex = False)\n",
    "    .str.replace(\",\" , \"\" , regex = False)\n",
    ")\n",
    "\n",
    "# then we need to convert it from a string to a float\n",
    "\n",
    "unique_data[\"Salary\"] = unique_data[\"Salary\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can scale all necessary columns with MinMaxScaler\n",
    "\n",
    "cols_to_scale = [\"FG\" , \"TRB\", \"AST\", \"STL\", \"BLK\", \"Salary\"]\n",
    "\n",
    "scaler = MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "unique_data[cols_to_scale] = scaler.fit_transform(unique_data[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the clustering algo with your best guess for K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a visualization of the results with 2 or 3 variables that you think will best\n",
    "#differentiate the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the quality of the clustering using total variance explained and silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the ideal number of clusters using the elbow method and the silhouette coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the results of the elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the recommended number of cluster (assuming it's different) to retrain your model and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once again evaluate the quality of the clustering using total variance explained and silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the model to select players for Mr. Rooney to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3214829668.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31man overview of how and why you made the choices you did. This should be at least\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Write up the results in a separate notebook with supporting visualizations and \n",
    "an overview of how and why you made the choices you did. This should be at least \n",
    "500 words and should be written for a non-technical audience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
